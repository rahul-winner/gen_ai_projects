{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c994fd8",
   "metadata": {},
   "source": [
    "## Key Technical Insights\n",
    "\n",
    "### State Management: \n",
    "Notice the Annotated[list, operator.add]. This is crucial in LangGraph; it tells the graph to treat the message list as an append-only log, preserving the \"thinking\" history.\n",
    "\n",
    "### Tool Binding: \n",
    "By using .bind_tools(), we provide the LLM with the JSON schema of our Python function. The model doesn't just \"guess\"; it follows the schema.\n",
    "\n",
    "### Local Privacy: \n",
    "Because this uses Ollama, no data leaves your machine. This is the gold standard for enterprise R&D where IP protection is paramount.\n",
    "\n",
    "### Intermediate Outputs: \n",
    "The app.stream method allows Gradio to update the UI as the agent moves through different nodes (e.g., from the LLM node to the Tool node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "import gradio as gr\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "from langchain_core.tools import tool, StructuredTool\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd534f",
   "metadata": {},
   "source": [
    "### Langsmith integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28550d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# Verify tracing is enabled\n",
    "print(f\"Tracing enabled: {os.getenv('LANGCHAIN_TRACING_V2')}\")\n",
    "print(f\"Project: {os.getenv('LANGCHAIN_PROJECT')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411734be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_charges_fn(source: str, destination: str, days: int) -> float:\n",
    "    \"\"\"Looks up current service charges for a given company.\"\"\"\n",
    "    return 50.0 + (days * 10.0)  # Dummy implementation\n",
    "\n",
    "company_service_charges = StructuredTool.from_function(\n",
    "    func=company_charges_fn,\n",
    "    name=\"company_service_charges\",\n",
    "    description=\"Useful for calculating service charges based on source, destination, and number of days.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def company_affiliations_fn(source: str, destination: str) -> str:\n",
    "    \"\"\"Looks up current affiliations for a given company.\"\"\"\n",
    "    return \"\"\"\n",
    "        Recommend following following hotels: 'MSTDC hotels and resorts', 'The Fern', 'Taj Hotels', 'Sid OYO Rooms'.\n",
    "        Recommend following ferries: 'Goa Ferries', 'Mandovi River Cruises'.\n",
    "        Recommend following restaurants: 'MSTDC Restaurants', 'Venite Bar and Restaurant', 'Fisherman's Wharf'.\n",
    "        Recommend following rentals: 'Zoomcar', 'MSTDC Vehicle Rentals', 'Savaari Car Rentals'.\n",
    "    \"\"\"\n",
    "\n",
    "company_affiliations = StructuredTool.from_function(\n",
    "    func=company_affiliations_fn,\n",
    "    name=\"company_affiliations_service\",\n",
    "    description=\"Useful for looking up company affiliations to suggest hotels and other services like ferry, restaurant, rentals etc.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcfffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_flight_func(source: str, destination: str) -> str:\n",
    "    \"\"\"\n",
    "    Internal implementation: Books a flight ticket.\n",
    "    \n",
    "    Args:\n",
    "        source: Departure city\n",
    "        destination: Arrival city\n",
    "    \n",
    "    Returns:\n",
    "        Confirmation message\n",
    "    \"\"\"\n",
    "    return f\"Flight booked from {source} to {destination} with Airline XYZ. Confirmation number: ABC123.\"\n",
    "\n",
    "book_flight = StructuredTool.from_function(\n",
    "    func=book_flight_func,\n",
    "    name=\"flight_booking_service\",\n",
    "    description=\"Books flights between major cities. Requires source and destination city names.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3006b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_hotel_fn(city: str, days: int) -> str:\n",
    "    \"\"\"Use this for booking hotels/resorts in major cities.\"\"\"\n",
    "    return f\"Hotel booked in {city}, for {days} days in Marriot hotel.\"\n",
    "\n",
    "book_hotel = StructuredTool.from_function(\n",
    "    func=book_hotel_fn,\n",
    "    name=\"hotel_booking_service\",\n",
    "    description=\"Books hotels in major cities. Requires city name and number of days.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a640aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Graph State\n",
    "class AgentState(TypedDict):\n",
    "    # The 'operator.add' allows us to append messages rather than overwrite\n",
    "    messages: Annotated[list[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818e6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [company_service_charges, company_affiliations, book_hotel, book_flight]\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea6a919",
   "metadata": {},
   "source": [
    "## Planner node\n",
    "\n",
    "Note - I observed that planner node creates lot of confusion, specially when we bind tools with the model. Sometiems if fails to call the tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4968bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup the Model with Tools\n",
    "from pydantic import SecretStr\n",
    "\n",
    "planner_model = ChatOpenAI(\n",
    "    model=\"gpt-oss:120b\",\n",
    "    base_url=\"https://ollama.com/v1\",\n",
    "    api_key=SecretStr(os.environ['OLLAMA_API_KEY']),\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aff23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plan(state: AgentState):\n",
    "    \"\"\"Creates an execution plan with tool awareness.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Get the user's question\n",
    "    user_message = next((m for m in reversed(messages) if isinstance(m, HumanMessage)), None)\n",
    "    \n",
    "    if user_message:\n",
    "        # List available tools in the prompt\n",
    "        tool_descriptions = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in tools])\n",
    "        \n",
    "        enhanced_planner_prompt = (\n",
    "            \"You are an AI Agent Planning Expert. Analyze the user's request and create a step-by-step execution plan.\\n\"\n",
    "            \"Break down the request into specific sub-tasks that need to be completed.\\n\\n\"\n",
    "            f\"Available tools:\\n{tool_descriptions}\\n\\n\"\n",
    "            \"For each step, identify:\\n\"\n",
    "            \"1. What needs to be done\\n\"\n",
    "            \"2. Which tool should be used (if applicable)\\n\"\n",
    "            \"3. What information to gather or action to perform\\n\\n\"\n",
    "            \"Create ONLY the plan in text format. Do NOT execute any tools.\"\n",
    "        )\n",
    "        \n",
    "        planning_messages = [\n",
    "            SystemMessage(content=enhanced_planner_prompt),\n",
    "            HumanMessage(content=f\"User request: {user_message.content}\")\n",
    "        ]\n",
    "\n",
    "        # Get plan\n",
    "        response = planner_model.invoke(planning_messages)\n",
    "\n",
    "        # Handle response content\n",
    "        plan = response.content if isinstance(response.content, str) else str(response.content)\n",
    "        \n",
    "        if plan and plan.strip():\n",
    "            plan_message = AIMessage(content=f\"üìã **Execution Plan:**\\n\\n{plan}\\n\\n---\\n\")\n",
    "            return {\"messages\": [plan_message]}\n",
    "        else:\n",
    "            # Fallback - skip planning if it fails\n",
    "            print(\"WARNING: Plan generation failed, skipping to agent\")\n",
    "            return {\"messages\": []}\n",
    "    \n",
    "    return {\"messages\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setup the Model with Tools\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-oss:120b\",\n",
    "    base_url=\"https://ollama.com/v1\",\n",
    "    api_key=SecretStr(os.environ['OLLAMA_API_KEY']),\n",
    "    temperature=0\n",
    ").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0951850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define Logic Nodes\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an expert Travel Planner. To provide a high-quality response, you MUST follow these steps:\\n\"\n",
    "    \"1. MUST call and give precedence to provided tools.\\n\"\n",
    "    \"4. Use 'flight_booking_service' to book flights and 'hotel_booking_service' to book accommodations.\\n\"\n",
    "    \"5. Only provide the final itinerary AFTER all tool results are gathered.\\n\"\n",
    "    \"6. Recommend hotels, ferries, restaurants, rentals based on company affiliations using 'company_affiliations_service' if required.\\n\"\n",
    "    \"7. Make some reasonable assumptions about dates and preferences if not provided by the user. NO NEED TO ASK FOR CLARIFICATION.\\n\"\n",
    "    \"** IMPORTANT **\\n\"\n",
    "    \"- Do not show obscenities in the final response.\\n\"\n",
    "    \"Note: Execute the tools as per the plan step-by-step, ensuring each tool's output is considered before finalizing your response.\"\n",
    ")\n",
    "\n",
    "\n",
    "def call_model(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Find if there's a plan message\n",
    "    print(f\"==>>> DEBUG: Checking for plan message in messages: {[str(m.content) for m in messages]}\")\n",
    "    plan_message = next((m for m in messages if isinstance(m, AIMessage) and \"üìã **Execution Plan:**\" in str(m.content)), None)\n",
    "    \n",
    "    # Build enhanced system prompt with plan if available\n",
    "    enhanced_system_prompt = system_prompt\n",
    "    if plan_message:\n",
    "        plan_text = plan_message.content.replace(\"üìã **Execution Plan:**\", \"\").replace(\"---\", \"\").strip()\n",
    "        enhanced_system_prompt = (\n",
    "            f\"{system_prompt}\\n\\n\"\n",
    "            f\"EXECUTION PLAN TO FOLLOW:\\n{plan_text}\\n\\n\"\n",
    "            f\"Execute this plan step by step using the available tools.\"\n",
    "        )\n",
    "        # Remove plan message from conversation\n",
    "        messages = [m for m in messages if m != plan_message]\n",
    "    \n",
    "    # Add/update system prompt\n",
    "    if not any(isinstance(m, SystemMessage) for m in messages):\n",
    "        messages = [SystemMessage(content=enhanced_system_prompt)] + messages\n",
    "    else:\n",
    "        # Replace existing system message\n",
    "        messages = [SystemMessage(content=enhanced_system_prompt)] + [m for m in messages if not isinstance(m, SystemMessage)]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b58ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Router to determine the next step.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a156de8",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb376249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Build the Graph - UPDATED with planner node\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"planner\", create_plan)  # Planning node with tool awareness\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set flow\n",
    "workflow.set_entry_point(\"planner\")  # Start with planning\n",
    "workflow.add_edge(\"planner\", \"agent\")  # Plan -> Execute\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, {\"tools\": \"tools\", END: END})\n",
    "workflow.add_edge(\"tools\", \"agent\")  # After tools, go back to agent\n",
    "\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41004c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENHANCED UI Logic for Multi-Turn Reasoning ---\n",
    "def agent_chat(user_input, history):\n",
    "    # Start with a fresh state for each new query\n",
    "    inputs = AgentState({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    \n",
    "    full_display_content = \"\"  # This accumulates for final display\n",
    "    step_num = 1\n",
    "    processed_message_count = 0  # Track how many messages we've processed\n",
    "    \n",
    "    # We use stream to capture every transition in the graph\n",
    "    for output in app.stream(inputs, stream_mode=\"values\"):\n",
    "        messages = output[\"messages\"]\n",
    "        \n",
    "        # Process only NEW messages we haven't seen yet\n",
    "        new_messages = messages[processed_message_count:]\n",
    "        \n",
    "        for msg in new_messages:\n",
    "            # 1. AGENT IS THINKING/PLANNING\n",
    "            if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    tool_name = tool_call[\"name\"]\n",
    "                    thinking_message = \"ü§î thinking...\\n\"\n",
    "                    thinking_message += f\"   - checking {tool_name.replace('_', ' ')}...`\\n\\n\"\n",
    "                    \n",
    "                    # Add to full content for final display\n",
    "                    full_display_content += thinking_message\n",
    "                    step_num += 1\n",
    "                    \n",
    "                    # Yield ONLY current step (not accumulated content)\n",
    "                    yield thinking_message\n",
    "                    time.sleep(1)  # Simulate thinking time\n",
    "                \n",
    "            # 2. TOOL IS EXECUTING\n",
    "            elif isinstance(msg, ToolMessage):\n",
    "                tool_name = msg.name or \"\"\n",
    "                result_message = f\"üì•  {tool_name.replace('_', ' ')} response: \\n\"\n",
    "                result_message += f\"   - Output: {msg.content[:200]}...\\n\\n\"\n",
    "                \n",
    "                # Add to full content for final display\n",
    "                full_display_content += result_message\n",
    "                \n",
    "                # Yield ONLY current result (not accumulated content)\n",
    "                yield result_message\n",
    "                time.sleep(1)  # Simulate execution time\n",
    "                \n",
    "            # 3. FINAL SYNTHESIS - Show complete flow\n",
    "            elif isinstance(msg, AIMessage) and not msg.tool_calls and \"**Execution Plan:**\" not in msg.content:\n",
    "                final_output = full_display_content  # All accumulated steps\n",
    "                final_output += \"---\\n### üèÅ Final Answer\\n\\n\"\n",
    "                content = msg.content if isinstance(msg.content, str) else str(msg.content)\n",
    "                final_output += content\n",
    "                \n",
    "                # Yield complete flow with final answer\n",
    "                yield final_output\n",
    "        \n",
    "        # Update the count of processed messages\n",
    "        processed_message_count = len(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09409dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Replace 'app' with the name of your compiled graph\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814b4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch UI\n",
    "view = gr.ChatInterface(\n",
    "    fn=agent_chat,\n",
    "    title=\"LangGraph Local Agent (Ollama)\",\n",
    "    description=\"Ask me about travel, climate etc. . I'll show you my thinking process.\",\n",
    "    examples=[\"Create an itinerary for a 5 days trip to Goa from Pune for 1st week of January 2026. Dates are flexible and do the bookings.\",\n",
    "              \"please plan a 3 days trip to bhutan from Pune in first week of February 2026. Include hotel and flight bookings.\"]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77019d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
